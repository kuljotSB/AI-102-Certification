{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e8f2d36",
   "metadata": {},
   "source": [
    "## Audio Enabled GenAI Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ddf673",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-ai-projects==2.0.0b2 openai==1.109.1 python-dotenv azure-identity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74d3d44",
   "metadata": {},
   "source": [
    "### Setting up the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d2097c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "import base64\n",
    "import requests\n",
    "load_dotenv()\n",
    "\n",
    "foundry_project_endpoint = os.getenv(\"FOUNDRY_PROJECT_ENDPOINT\")\n",
    "model_deployment_name = os.getenv(\"MODEL_DEPLOYMENT_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91084fe3",
   "metadata": {},
   "source": [
    "### Setting up the AI Foundry Project Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2fdaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_client = AIProjectClient(\n",
    "    endpoint=foundry_project_endpoint,\n",
    "    credential=DefaultAzureCredential()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8e6ebd",
   "metadata": {},
   "source": [
    "### Setting up the OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1802a2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = project_client.get_openai_client(api_version=\"2024-10-21\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4d774b",
   "metadata": {},
   "source": [
    "### Encoding the Audio Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053f3b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the audio file\n",
    "file_path = \"https://raw.githubusercontent.com/kuljotSB/AI-102-Certification/raw/refs/heads/main/AzureLanguageService/Audio-Enabled-GenAI-App/avocados.mp3\"\n",
    "response = requests.get(file_path)\n",
    "response.raise_for_status()\n",
    "audio_data = base64.b64encode(response.content).decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63021715",
   "metadata": {},
   "source": [
    "### Sending a Request to the Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d16274",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = openai_client.messages.create(\n",
    "    model = model_deployment_name,\n",
    "    messages=[\n",
    "       {\"role\": \"system\", \"content\": \"You are a helpful Audio-Enabled AI assistant.\"},\n",
    "       { \"role\": \"user\",\n",
    "           \"content\": [\n",
    "           { \n",
    "               \"type\": \"text\",\n",
    "               \"text\": \"Summarize the audio content.\"\n",
    "           },\n",
    "           {\n",
    "               \"type\": \"input_audio\",\n",
    "               \"input_audio\": {\n",
    "                   \"data\": audio_data,\n",
    "                   \"format\": \"mp3\"\n",
    "               }\n",
    "           }\n",
    "       ] }\n",
    "   ],\n",
    "    max_tokens=1024\n",
    ")\n",
    "\n",
    "json_message = message.to_dict()\n",
    "print(json_message['content'][0]['text'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
