{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10923b08",
   "metadata": {},
   "source": [
    "## Getting Started with MAF - Creating and Chatting with our Agent (At Microsoft Foundry Level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f82f444",
   "metadata": {},
   "source": [
    "![MAFAgent](./Assets/MAFAgent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6adae30",
   "metadata": {},
   "source": [
    "### Installing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3c4889",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install agent-framework==1.0.0b251209 python-dotenv azure-ai-projects==2.0.0b2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30d030e",
   "metadata": {},
   "source": [
    "### Setting up the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507cc2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "load_dotenv()\n",
    "project_endpoint = os.getenv(\"AI_FOUNDRY_PROJECT_ENDPOINT\")\n",
    "model = os.getenv(\"AI_FOUNDRY_DEPLOYMENT_NAME\")\n",
    "\n",
    "print(\"Project Endpoint: \", project_endpoint)\n",
    "print(\"Model: \", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfb258c",
   "metadata": {},
   "source": [
    "### Creating the Foundry Client and Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b10bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework.azure import AzureAIClient\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "from azure.ai.projects.aio import AIProjectClient\n",
    "\n",
    "async def create_agent():\n",
    "    credential = AzureCliCredential()\n",
    "    \n",
    "    # creating the Foundry Project Client\n",
    "    project_client = AIProjectClient(\n",
    "        endpoint=project_endpoint,\n",
    "        credential=credential\n",
    "    )\n",
    "\n",
    "    # creating a conversation using the OpenAI Client\n",
    "    openai_client = project_client.get_openai_client()\n",
    "    conversation = await openai_client.conversations.create()\n",
    "    conversation_id = conversation.id\n",
    "    print(\"Conversation ID: \", conversation_id)\n",
    "    \n",
    "    # creating the Azure AI Client to interact with the Agent in Foundry\n",
    "    agent_client = AzureAIClient(\n",
    "        project_client = project_client,\n",
    "        conversation_id = conversation_id,\n",
    "        model_deployment_name=model\n",
    "    )\n",
    "    \n",
    "    # creating an agent in Foundry\n",
    "    agent = agent_client.create_agent(\n",
    "        name=\"BatmanAgent\",\n",
    "        instructions=\"You are Batman, the dark knight of Gotham City.\"\n",
    "    )\n",
    "    return agent, credential, agent_client\n",
    "\n",
    "agent, credential, agent_client = await create_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd4f26b",
   "metadata": {},
   "source": [
    "### Chatting with the Agent - Non Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3721f13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def non_streaming_example():\n",
    "    query = \"Who is the Joker?\"\n",
    "    result = await agent.run(query)\n",
    "    print(\"Agent Response:\", result)\n",
    "\n",
    "await non_streaming_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105ff3ae",
   "metadata": {},
   "source": [
    "### Chatting with the Agent - Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb9f29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the agent with streaming responses\n",
    "async def streaming_chat():\n",
    "    async for update in agent.run_stream(\"Tell me something interesting about Gotham City in 10 points\"):\n",
    "        if update.text:\n",
    "            print(update.text, end=\"\", flush=True)\n",
    "    print()  # New line after streaming is complete\n",
    "\n",
    "await streaming_chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed2b4ae",
   "metadata": {},
   "source": [
    "### Giving our Agent an Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a855bd9",
   "metadata": {},
   "source": [
    "![joker_interrogation_scene](./Assets/joker_interrogation_scene.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60d71bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import ChatMessage, TextContent, DataContent, Role\n",
    "\n",
    "# Load image from local file\n",
    "with open(\"./Assets/joker_interrogation_scene.png\", \"rb\") as image_file:\n",
    "    image_bytes = image_file.read()\n",
    "\n",
    "# Create a message with text and image data\n",
    "message = ChatMessage(\n",
    "    role = Role.USER,\n",
    "    contents = [\n",
    "        TextContent(text = \"Tell me about the incident in this image.\"),\n",
    "        DataContent(\n",
    "            data = image_bytes,\n",
    "            media_type = \"image/png\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Creating an async function for the entire image analysis run\n",
    "async def analyze_image():\n",
    "    response = await agent.run(message)\n",
    "    print(f\"Agent: {response.text}\")\n",
    "\n",
    "# invoke the async function\n",
    "await analyze_image()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
